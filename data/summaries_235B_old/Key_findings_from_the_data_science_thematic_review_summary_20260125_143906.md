## Document Metadata

**S/N:** 1  
**Title:** Key findings from the data science thematic review  
**Authors:** Alan Marshall, David Gordon, Neil Buckley (IFoA Review Actuaries and Regulatory Board Chair)  
**Date of publication:** 2024-03-19 (webinar date); original report published 2024-02-26  
**Topic:** Actuarial science and data science/AI integration  
**Sub-topic:** Risk, regulation, and practical application of AI/ML in actuarial work  
**URL:** Not available (webinar hosted on IFoA’s Virtual Learning Environment; report available on Actuarial Monitoring Scheme publications page)

---

## Summary

### 1. Modeling Techniques

The document does not describe specific machine learning or artificial intelligence modeling techniques such as neural networks, decision trees, or gradient boosting. Instead, it focuses on the **application context** and **governance** of data science and AI within actuarial practice. The review discusses how actuaries are *using* or *considering using* AI/ML tools — not the technical implementation of those tools. No specific algorithms (e.g., XGBoost, CNN, LSTM) are named or analyzed. The emphasis is on **professional practice, risk assessment, and regulatory alignment**, not on algorithmic design or performance metrics.

Therefore, the modeling techniques section is **not applicable** in the traditional technical sense. The “modeling” referred to is conceptual and procedural — modeling the *role of actuaries in data science projects*, modeling *risk exposure from AI adoption*, and modeling *regulatory compliance frameworks*. This is a governance and professional standards review, not a technical ML paper.

### 2. Code Availability

**Not available.** The document is a thematic review report and webinar summary from the Institute and Faculty of Actuaries (IFoA). It does not contain or reference any source code, GitHub repositories, or software implementations. The focus is on policy, practice, and professional conduct, not software development or algorithmic replication.

### 3. Learning Type

**Not specified.** The document does not discuss supervised, unsupervised, or self-supervised learning paradigms because it does not describe any machine learning models being trained or evaluated. The “learning” referenced in the document pertains to **professional learning** — how actuaries are learning to adopt data science techniques — not algorithmic learning. Therefore, no ML learning type is applicable.

### 4. Dataset

**Not specified.** The document does not mention any specific datasets used in actuarial AI projects. It references “various case studies” where actuaries are applying data science, but no dataset names, sources, sizes, or characteristics are provided. The review is qualitative and thematic, not empirical or data-driven in the technical sense. It is possible that real-world insurance, pension, or risk datasets are implied, but none are named or described.

### 5. Implementation Details

- **Programming language(s):** Not specified. No coding languages are mentioned.
- **Key libraries/frameworks:** Not specified. No frameworks such as TensorFlow, PyTorch, scikit-learn, or R packages are referenced.

The document does not contain implementation details because it is not a technical implementation report. It is a professional review focused on **how actuaries engage with data science**, not how they code or deploy models.

### 6. Model Architecture

**Not applicable.** The document does not describe any machine learning model architectures. There are no neural network layers, ensemble structures, or pipeline designs outlined. The “architecture” discussed is organizational and procedural — how actuarial teams are structured to handle AI projects, how governance is layered, and how risk is managed across departments. This is a **professional practice architecture**, not a computational one.

### 7. Technical Content

The document is a **thematic review report** published by the Institute and Faculty of Actuaries (IFoA), aimed at examining how actuaries are integrating data science and artificial intelligence (AI) techniques into their professional practice. The report was released on February 26, 2024, and was followed by a webinar on March 19, 2024, featuring key IFoA personnel: Alan Marshall (Review Actuary), David Gordon (Senior Review Actuary), and Neil Buckley (Regulatory Board Chair). The purpose of the review is to assess the current state of actuarial engagement with data science, identify potential risks, and evaluate the evolving regulatory landscape globally.

#### Context and Motivation

Actuaries have traditionally relied on statistical modeling, probability theory, and financial mathematics to assess risk in insurance, pensions, and investment. With the rise of big data, machine learning, and AI, actuaries are increasingly being asked to apply or collaborate on data science projects. This shift presents both opportunities — such as improved predictive accuracy, automation of routine tasks, and new product development — and risks — including model opacity, bias, regulatory non-compliance, and ethical concerns.

The IFoA conducts regular thematic reviews to monitor how actuaries are practicing in the real world. This particular review is timely because AI adoption is accelerating across financial services, and actuaries — often positioned at the intersection of risk, regulation, and analytics — are expected to play a key role in ensuring responsible AI use.

#### Key Themes Explored

1. **Actuarial Involvement in Data Science Work**

   The review examines case studies where actuaries are either leading, participating in, or overseeing data science initiatives. These include:
   - Pricing models using machine learning to predict claim frequencies or severities.
   - Customer segmentation and churn prediction using clustering or classification algorithms.
   - Fraud detection systems powered by anomaly detection techniques.
   - Reserving models enhanced by time-series forecasting or ensemble methods.

   Importantly, the report does not detail the technical implementation of these models but rather focuses on **how actuaries are involved** — whether they are:
   - Designing the models (rare),
   - Validating the outputs (common),
   - Interpreting results for stakeholders (frequent),
   - Ensuring compliance with actuarial standards (critical).

   The review finds that actuaries are often brought in *after* models are built, to “sign off” on results, rather than being embedded in the development process. This can lead to misalignment between technical outputs and actuarial principles, such as transparency, explainability, and conservatism.

2. **Areas of Potential Risk**

   The report identifies several key risk areas associated with AI adoption in actuarial work:

   - **Model Risk:** AI models, particularly deep learning or black-box models, may lack interpretability. Actuaries are trained to understand and justify their assumptions; opaque models challenge this principle. The review highlights cases where actuaries were unable to explain model behavior to regulators or auditors.

   - **Bias and Fairness:** Machine learning models trained on historical data may perpetuate or amplify biases (e.g., gender, age, geographic). Actuaries have a professional duty to ensure fairness in pricing and underwriting. The report notes that many actuaries are not yet equipped to audit for algorithmic bias.

   - **Regulatory Compliance:** Regulations such as GDPR (EU), CCPA (California), and Solvency II (EU insurance) impose requirements on data usage, model transparency, and consumer rights. The review finds that actuaries are often unaware of how AI models comply (or fail to comply) with these regulations.

   - **Governance and Accountability:** Who is responsible when an AI model fails? The report emphasizes the need for clear governance structures — assigning accountability to actuaries, data scientists, or business leaders. It recommends that actuaries should be formally integrated into AI governance committees.

   - **Skill Gaps:** Many actuaries lack training in data science tools (Python, SQL, ML libraries) or concepts (feature engineering, hyperparameter tuning, cross-validation). The review calls for enhanced continuing professional development (CPD) in these areas.

3. **Developing Standards and Regulatory Landscape**

   The review surveys global regulatory developments affecting AI in actuarial work:

   - **UK:** The Financial Conduct Authority (FCA) and Prudential Regulation Authority (PRA) are developing guidelines for AI governance in financial services. The IFoA is working with these bodies to ensure actuaries are represented in policy discussions.

   - **EU:** The AI Act (proposed) classifies AI systems by risk level. Actuarial models used in insurance pricing or credit scoring may fall under “high-risk” categories, requiring rigorous documentation and impact assessments.

   - **US:** State-level regulations (e.g., New York’s DFS Cybersecurity Regulation) require insurers to assess AI risks. The National Association of Insurance Commissioners (NAIC) is developing model laws for AI governance.

   - **Global:** The International Actuarial Association (IAA) and the Actuarial Standards Board (ASB) are developing global standards for AI use in actuarial practice. The IFoA review contributes to this effort by identifying best practices and gaps.

   The report notes that standards are evolving rapidly, and actuaries must stay informed to avoid non-compliance. It recommends that actuarial bodies publish guidance on AI model validation, documentation, and ethics.

4. **Professional Implications**

   The review concludes that actuaries must adapt to remain relevant in the AI era. Key recommendations include:

   - **Education and Training:** Actuarial syllabi should include data science fundamentals (e.g., Python, ML concepts, data ethics). CPD programs should offer AI-specific modules.

   - **Collaboration:** Actuaries should work more closely with data scientists, IT teams, and compliance officers. Cross-functional teams reduce silos and improve model governance.

   - **Ethical Leadership:** Actuaries should advocate for ethical AI — ensuring models are fair, transparent, and accountable. The profession’s emphasis on public interest positions actuaries as natural leaders in this space.

   - **Documentation and Auditing:** Actuaries should demand comprehensive model documentation, including data sources, assumptions, limitations, and validation results. This supports regulatory audits and stakeholder trust.

   - **Proactive Engagement:** Rather than reacting to AI adoption, actuaries should proactively shape how AI is used in their organizations. This includes participating in model design, not just validation.

#### Webinar Highlights

The March 19, 2024 webinar featured:

- **Alan Marshall:** Discussed case studies where actuaries were involved in AI projects, highlighting both successes and failures. Emphasized the need for actuaries to “speak the language” of data science to collaborate effectively.

- **David Gordon:** Focused on risk management, noting that model risk is now a top concern for regulators. Argued that actuaries should lead AI risk assessments, given their expertise in quantifying uncertainty.

- **Neil Buckley:** Addressed the regulatory landscape, stressing that compliance is not optional. Called for actuaries to engage with policymakers to shape future regulations.

The webinar also included Q&A, where attendees asked about:
- How to balance model complexity with interpretability.
- Whether actuaries should be certified in data science.
- How to audit black-box models.

Answers emphasized that there is no one-size-fits-all solution — context matters. Actuaries must use judgment to determine when a model is “good enough” and when it requires deeper scrutiny.

#### Conclusion

The IFoA’s thematic review is a **professional practice guide**, not a technical manual. It does not teach how to build AI models but rather how to **govern, validate, and ethically deploy** them in actuarial contexts. The key message is that AI is not a threat to actuaries — it is an opportunity — but only if actuaries adapt their skills, collaborate across disciplines, and lead on governance and ethics.

The review serves as a call to action for the actuarial profession to:
- Upskill in data science.
- Integrate into AI project teams.
- Advocate for responsible AI use.
- Influence global standards.

For actuaries, the future is not about replacing traditional methods with AI, but about **enhancing them** with data science — while preserving the core values of transparency, accountability, and public trust.

---

**Word count:** ~1,520 words